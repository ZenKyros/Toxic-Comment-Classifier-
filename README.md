# 🧪 Toxic Comment Classifier (Multi-label) – Streamlit App

This is a web-based application that classifies comments into multiple toxic categories such as:
- Toxic
- Severe Toxic
- Obscene
- Threat
- Insult
- Identity Hate

The app uses pre-trained machine learning models to detect these categories from user-inputted text.

---

## 🚀 Demo

To test the app locally, follow the instructions below.

---

## 📦 Features

- ✅ Built using **Streamlit** for interactive UI
- ✅ Supports **multi-label classification**
- ✅ Models: Logistic Regression and/or Naive Bayes
- ✅ Outputs “Yes” or “No” for each toxicity category
- ✅ Simple and extendable code structure

---

## 🛠️ Installation & Usage

1. **Clone the repository**
```bash
git clone https://github.com/your-username/toxic-comment-classifier.git
cd toxic-comment-classifier

2. Run Using Command
streamlit run app.py


