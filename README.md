# ğŸ§ª Toxic Comment Classifier (Multi-label) â€“ Streamlit App

This is a web-based application that classifies comments into multiple toxic categories such as:
- Toxic
- Severe Toxic
- Obscene
- Threat
- Insult
- Identity Hate

The app uses pre-trained machine learning models to detect these categories from user-inputted text.

---

## ğŸš€ Demo

To test the app locally, follow the instructions below.

---

## ğŸ“¦ Features

- âœ… Built using **Streamlit** for interactive UI
- âœ… Supports **multi-label classification**
- âœ… Models: Logistic Regression and/or Naive Bayes
- âœ… Outputs â€œYesâ€ or â€œNoâ€ for each toxicity category
- âœ… Simple and extendable code structure

---

## ğŸ› ï¸ Installation & Usage

1. **Clone the repository**
```bash
git clone https://github.com/your-username/toxic-comment-classifier.git
cd toxic-comment-classifier

2. Run Using Command
streamlit run app.py


